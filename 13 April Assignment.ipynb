{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53c05f-bdcc-4b48-b45d-15c3090d297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "\n",
    "The Random Forest Regressor is a machine learning algorithm that belongs to the ensemble learning family. It is an extension of the Random Forest algorithm, which is commonly used for both classification and regression tasks. In the case of Random Forest Regressor, the algorithm is specifically designed for regression problems, where the goal is to predict a continuous numerical output.\n",
    "\n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "\n",
    "Random Forest Regressor reduces the risk of overfitting through the following mechanisms:\n",
    "\n",
    "Ensemble of Trees: It builds multiple decision trees on different subsets of the training data, introducing diversity. This helps prevent the model from memorizing the training data and overfitting to noise.\n",
    "Random Feature Selection: It randomly selects a subset of features for each tree, ensuring that each tree is trained on a different set of features. This further contributes to the model's generalization ability.\n",
    "\n",
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "\n",
    "Random Forest Regressor aggregates the predictions of multiple decision trees by taking the average of their individual predictions. For each input, each tree in the forest produces a prediction, and the final prediction for the Random Forest Regressor is the average (or mean) of these individual tree predictions.\n",
    "\n",
    "\n",
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "\n",
    "Some of the important hyperparameters of the Random Forest Regressor include:\n",
    "\n",
    "n_estimators: The number of trees in the forest.\n",
    "max_depth: The maximum depth of each tree.\n",
    "min_samples_split: The minimum number of samples required to split an internal node.\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "max_features: The number of features to consider when looking for the best split.\n",
    "\n",
    "\n",
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "\n",
    "Ensemble vs. Single Tree: The main difference is that Random Forest Regressor is an ensemble of multiple decision trees, whereas Decision Tree Regressor is a single decision tree.\n",
    "Overfitting: Random Forest Regressor is less prone to overfitting compared to Decision Tree Regressor, thanks to the ensemble approach and random feature selection.\n",
    "Prediction Aggregation: Random Forest Regressor aggregates predictions by averaging (for regression tasks), while Decision Tree Regressor provides a single prediction.\n",
    "\n",
    "\n",
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Reduced Overfitting: Thanks to the ensemble approach.\n",
    "Handles Non-linearity: Can capture complex relationships in data.\n",
    "Robust to Outliers: Less sensitive to outliers compared to a single decision tree.\n",
    "Disadvantages:\n",
    "\n",
    "Black Box Model: Interpretability can be challenging.\n",
    "Computational Complexity: Training and prediction can be computationally expensive.\n",
    "Hyperparameter Tuning: Requires careful tuning of hyperparameters.\n",
    "\n",
    "Q7. What is the output of Random Forest Regressor?\n",
    "\n",
    "The output of a Random Forest Regressor is a continuous numerical prediction. For each input instance, the model produces a prediction that represents the average (mean) of the predictions made by individual decision trees in the ensemble.\n",
    "\n",
    "\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "\n",
    "While Random Forest Regressor is specifically designed for regression tasks (predicting continuous numerical values), the Random Forest algorithm as a whole can be used for both classification and regression. For classification tasks, you would use the Random Forest Classifier, which predicts categorical outcomes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
